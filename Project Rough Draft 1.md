						**AI paper**   
To understand AI and how it is viewed in public consciousness, it is paramount to view the history of what AI means and how it was envisioned at its earliest inception. The term AI itself was coined in 1956 in a summer research project proposal at Dartmouth college by John McCarthy, an Assistant Math Professor \[1\]. His ambitious vision for this project was to have, “every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it”. A lot has changed since McCarthy’s time, when AI was merely in its inception. For one, the term itself has become more widespread than ever before, with firms and consumers knowing and unknowingly interacting with AI systems. Thus the goal set upon the field of AI is augmenting the ability of computers to simulate intelligence. Whether AI currently achieves this goal is ambiguous and differs depending on what one identifies intelligence is.   
One pitfall that lies at the heart of defining intelligence is the innate bias to superimpose so-called human faculties of intelligence, a form of confirmation bias. This can be seen even before AI, demonstrated in the arguments that Crawford proposes, that AI is neither artificial nor intelligent \[2\]. Crawford uses the example of the case of Clever Hans, a horse that appeared to know how to do basic arithmetic, but in reality just relied on the facial expression of its trainer to stop counting once it reached the desired answer. While the horse could not truly learn how to count, the fame and notoriety this spectacle created was immense at the start of the 20th century in many newspapers of the time \[3\]. The rise of AI and the hype surrounding it can be seen through many industries. This can be shown in a recent study that estimated the amount of investments in AI are around 140 billion dollars per year \[4\].   
While machines are more sophisticated than horses, this can also be a contributing factor for people being less hesitant on what these systems can do. This is in part due to many AI systems that consumers directly interact with, that being different forms of chatbots. Chatbots such as ChatGPT-4 have been shown to pass multiple different Turing tests, where behavioral and personality tests are statistically indistinguishable from human responses \[5\]. Another study used ChatGPT to observe how well it understood the sentiment of human text of various product views, using a sentiment analysis scoring system \[6\]. While it might seem that AI can seemingly mimic human intellect, this is far from the case. In the previous study, AI chatbots struggled to pick up on sarcasm. This lack of picking up on nuanced human text is a seemingly trivial error that in the next few years, could very well be fixed. But the very undergirding at which the misunderstandings between humans and AI communication are minute at best and devastating at worst.   
In the movie “I Robot”, based on the short story “Runaround” by Isaac Asimov, is set in Chicago in the year 2035 in which humans and robots coexist. There exists a set of laws programmed into each robot which follows,” The First Law states, A robot may not injure a human being or, through inaction, allow a human being to come to harm. The Second Law states, A robot must obey the orders given it by human beings except where such orders would conflict with the First Law. The Third Law states, a robot must protect its own existence as long as such protection does not conflict with the First or Second Law.” *(use a picture for this if it ends up in the final draft*). While these straightforward laws exist in a fictional universe, we are currently only a decade away in which this fictional setting takes place. There are issues surrounding a concrete set of standards of AI regulation that are currently not in place. The results of a lack of standard practice of AI ethics has the potential to put vulnerable people in danger in the hands of those who design and implement AI systems.  
One such recent problem that AI has contributed to is the social isolation and encouragement of unhealthy parasocial relationships. While parasocial relationships have existed since the early days of televisions and celebrity culture, AI shifts the perception of exclusivity and plays more into realizing people's fantasies. One way that this is being used currently is via online celebrities or other famous figures automating text responses. Recently, Meta has rolled out their own version of AI chatbots that aim to mimic celebrity figures or people with different character traits and backgrounds \[7\]. One such user who tested the Meta AI chatbots remarked how they were mostly unhelpful, that just looking information up or using a general AI chatbot would be more useful \[8\]. Many of these personalized Meta AI chatbots were only limited to a certain domain of expertise, such as the chief only providing cooking tips. I think the goals of these companies are not to make the user's experience on the platform more effective but to drive their user engagement up by attempting to simulate real people. This simulation of real people is not just made for a novel or interesting way to engage with such services, but can be seen as a desperate attempt to drive engagements on social media platforms.  
Another way that AI chatbots are being utilized is not by specific social media platforms themselves to drive user engagement, but also as a way of advertising. This can be seen on many social media platforms, but the most notable is Reddit. The main appeal of Reddit with advertisers targeting this platform in particular is how human driven the discussion topics are. These discussion topics create an open forum for anyone to comment on, with many of these forum posters either asking questions or addressing other users' responses. Where the AI chatbot advertising takes place is how it could be used to seem as a natural person suggesting that a certain product could help them with their problem. An example of this could start with the thread about how a user is trying to find a glue to fix their expensive figure. Wherein, the advertiser AI chatbot could be used to detect these types of questions and respond to the person saying that they should try their glue to fix the problem. The infiltration of these advertising AI chatbots could ruin the reputation of these sites, which would reduce the amount of users on sites like Reddit. In the long run this would become a lose-lose situation for all parties involved. The users, with how they are bombarded with synthetic advertisements, the websites losing massive amounts of users thus reducing the sites value for advertisers, and the advertisers themselves with less potential customers to advertise to.

Another example is when a lawyer submitted a brief that was created by ChatGPT. 

This next section of this paper will talk more in depth about how AI can help firms save on costs as well as generate more revenue. This section of the paper will also talk about what factors go into firms being able to utilize AI.  It will also talk about what types of firms and industries benefit the most from implementing AI. The last part of this paper will also talk about which are and are not highly susceptible to AI.  
One of the main concerns with the rise of AI development is that it will be used to replace people's jobs. This issue of people getting replaced or “phased” out by machines is not a novel concept. From the rise of agriculture in early human history, where man utilized the environment to grow the crops in front of them rather than having to spread out and seek them. As well as during the industrial revolution where man utilized technology instead of livestock, pulling heavy loads and generating energy through utilizing flowing water with mills. These two examples of the development of agriculture and the industrial revolution demonstrate mankind's ability to automate through the means of manipulating objects in the physical world.   
There is also a similar development of change which considers the modern era via means of manipulating and innovating the spread of information. The earliest examples of information being transferred can be seen within many ancient cultures via oral traditions being passed down from generation to generation. However, with the invention of the printing press, information could be stored within the confines of pages, where the archival  of information was formed. This spread of information was further extended in the development of the Internet, with knowledge not just spreading physically, but digitally with nearly any peice of information being stored in the average person's pocket. With the adoption of the internet, there became an exponential spread of information and data. Just as the internet became a way for information to spread across the world with astonishing speed, the age of AI further utilizes vast amounts of information stored in the virtual world. The commonality of all forms of AI is that it seeks to shift the burden of information gathering and processing from man to machine. Just as Upton Sinclair raised concern of the industrial revolution with his groundbreaking book, “The Jungle” showing disgusting malpractices in packing factories. The parallels in our time could not be more accurate, with scandals such as attorneys attempting to use AI to read through a case. In a world where one day the outcome of a person on trial is in the mechanical hands of a machine rather than man is one in which mankind must be observant.  
Before going further it is important to note what types of tasks AI is well suited for. These such tasks include those that heavily rely on detecting patterns, making judgments, and optimization \[9\]. AI excels at processing vast amounts of data at high speeds as well as being able to siphon large amounts of data from the internet. Another way in which AI is used is to identify correlations that may be imperceptible to humans. AI also can automate repetitive tasks, reducing human error. These are tasks that are within the AI domain are done by people who are highly skilled workers. This includes clinical laboratory technicians, chemical engineers, optometrists, and power plant operators \[9\].    
However, despite these strengths, AI still struggles with tasks that require deep contextual understanding, emotional intelligence, and nuanced decision-making, which remain the domain of human expertise. Jobs containing these certain aspects are less likely to be impacted by AI. These jobs would be careers such as teachers, veterinary technicians and entertainers \[9\].  
AI can be used in many different fields and industries. One example is how it can be used to reduce human errors in breast cancer screening \[10\]. While the use of AI technology can be used to evaluate certain images, studies show that many people would not go forth with an evaluation if they knew AI was used \[10\]. This lies  at the heart of the issue with AI, in that in some instances it is superior to humans but at the same time not be trusted. The underlying reason is that one cannot place the burden of blame on AI. This is due to the fact that AI is a moral agent and is a tool used by people \[11\]. One of the main reasons for this is that it cannot explain reasonings. Thus some people claim that the  use of AI should not be placed in positions where it can control the outcomes of one’s life. But what about the cases in which humans make decisions that can determine the outcome of people’s lives? Is it that people feel more comfortable in having a person be the morale agent, as they can be held responsible if the outcomes do not fare well. Or is it that currently we do not trust AI until it has become more trustworthy in the public?. Once AI has gained better press will it be used in life or death situations? Who will be the agent to blame if AI  does perform a miscalculation? While the answers to these questions are out of the scope of this paper, it is important to think about who is ultimately in charge of AI systems when they fail in their intended purpose as non-moral agents in determining life or death consequences in a position of higher authority.   
This same argument can be said for fields in which life or death decisions are made. This comes from the example of a court case in which a lawyer submitted a case brief that was written by ChatGPT. The field of law is a perfect example of where AI tools ride a fine line between being a useful tool and resulting in someone serving an unjust prison sentence. ChatGPT has proven that it is trained on legal issues, being shown to pass the bar exam with a C+ average score \[12\]. While ChatGPT appears to have legal issues in its training, it has also shown to often fabricate or “hallucinate” information on cases or completely make up court cases \[13\]. However, there is quite a conundrum with the introduction of AI not just by lawyers *talking about the case of an attorney using AI* in the field of law with the use of  the average person. While on one hand it gives people more access to justice, as people who do not have the financial means to a lawyer can prompt tools like ChatGPT for their specific case. But due to ChatGPT not being fully trustworthy, it could lead to people making unwise legal decisions. While there have existed legal tools such as Justicebot, which focus more on specific legal cases of landlord disputes, it is not as versatile as ChatGPT with responses to specific questions, but is far more accurate on legal information \[13\].   
This section of the paper will talk about the research and interest of using AI in advertising. This will explore how it is currently used and what further development of AI will lead to. I predict that AI advertising will eventually overtake natural and organic human communication on the internet, resulting in a dead internet type of effect.   
Advertising is a business that relies on being able to capture the attention of a select demographic of a certain product. The main gaps in advertising is who is the target audience that would be interested in buying a specific product and how platforms or means to reach these future customers on. One task that AI does really well is being able to predict, classify, and cluster trends in data. This data is valuable to these companies as the more they know about their customers the more data they have on them, the more accurately they can predict the customer.   
The dead internet theory became a popular conspiracy theory in the late 2010s which claims that the internet was controlled by bots, AI, and content curated algorithms pushed by big tech. As well as claims that most users one interacts with in the internet are not real people but bots (Dead internet theory). While this theory is largely disproven, it does however raise valid concerns that the use of AI on the internet at large. These concerns include drowning out organic human engagement, the spread of misinformation and the weakening of online communities (Dead internet theory). With the internet becoming more and more commercialized, AI can be used as a means to an end or as a catalyst of spam and online solicitation. *While it might seem like this is a unique problem only applying to AI, this line of similar arguments can be seen in the modern attention economy.* 

Bibliography  
\[1\]	TechScribe, “A Comprehensive Guide To The History Of Artificial Intelligence: Foundational Concepts And Early Developments.” Accessed: Mar. 18, 2025\. \[Online\]. Available: https://quantumzeitgeist.com/history-of-artificial-intelligence/  
\[2\]	K. Crawford, *The Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence*. Yale University Press, 2021\.  
\[3\]	“Berlin’s Wonderful Horse New York Times.pdf.” Accessed: Mar. 18, 2025\. \[Online\]. Available: https://timesmachine.nytimes.com/timesmachine/1904/09/04/101396572.pdf  
\[4\]	T. Babina, A. Fedyk, A. He, and J. Hodson, “Artificial intelligence, firm growth, and product innovation,” *J. Financ. Econ.*, vol. 151, p. 103745, Jan. 2024, doi: 10.1016/j.jfineco.2023.103745.  
\[5\]	Q. Mei, Y. Xie, W. Yuan, and M. O. Jackson, “A Turing test of whether AI chatbots are behaviorally similar to humans,” *Proc. Natl. Acad. Sci. U. S. A.*, vol. 121, no. 9, p. e2313925121, doi: 10.1073/pnas.2313925121.  
\[6\]	M. Belal, J. She, and S. Wong, “Leveraging ChatGPT As Text Annotation Tool For Sentiment Analysis,” Jun. 18, 2023, *arXiv*: arXiv:2306.17177. Accessed: Nov. 10, 2024\. \[Online\]. Available: http://arxiv.org/abs/2306.17177  
\[7\]	M. Andrejevic and Z. Volcic, “Automated Parasociality: From Personalization to Personification,” *Telev. New Media*, p. 15274764241300436, Nov. 2024, doi: 10.1177/15274764241300436.  
\[8\]	“I tested Meta’s Tom Brady and Kendall Jenner AI chatbots and it was weird | ZDNET.” Accessed: Mar. 20, 2025\. \[Online\]. Available: https://www.zdnet.com/article/i-tested-metas-tom-brady-and-kendall-jenner-ai-chatbots-and-it-was-weird/  
\[9\]	M. Webb, “The Impact of Artiﬁcial Intelligence on the Labor Market”.  
\[10\]	P. Esmaeilzadeh, “Use of AI-based tools for healthcare purposes: a survey study from consumers’ perspectives,” *BMC Med. Inform. Decis. Mak.*, vol. 20, no. 1, p. 170, Jul. 2020, doi: 10.1186/s12911-020-01191-1.  
\[11\]	J.-C. Heilinger, “The Ethics of AI Ethics. A Constructive Critique,” *Philos. Technol.*, vol. 35, no. 3, p. 61, Jul. 2022, doi: 10.1007/s13347-022-00557-9.  
\[12\]	K. Y. Iu and V. M.-Y. Wong, “ChatGPT by OpenAI: The End of Litigation Lawyers?,” *SSRN Electron. J.*, 2023, doi: 10.2139/ssrn.4339839.  
\[13\]	J. Tan, H. Westermann, and K. Benyekhlef, “ChatGPT as an Artificial Lawyer?”.

       


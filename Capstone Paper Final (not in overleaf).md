			**The Rise of AI: Ethics, Integration, and the Human Cost**  
**Abstract \-**   
This paper examines the societal and ethical implications of AI, arguing that many of the challenges it presents are not entirely unprecedented, reflecting recurring historical trends. While problems such as the usage of Big Data, targeted advertising, and parasocial relationships may be familiar, there has yet to be any consensus on how to tackle these issues. As AI continues to integrate into everyday life issues such as corporate monopolization of user generated data, algorithmic manipulation through targeted advertising and the spread of AI generated content in digital discourse. As well as the normalization of AI systems raises concerns about the rise of parasocial relationships, especially among vulnerable individuals. This paper underscores the need for a critical and ethically grounded approach to AI development, ensuring that technological progress serves the broader interests of humanity.

**Introduction \-**   
**AI and its current capabilities** 

This paper explores the broader societal implications of artificial intelligence (AI), focusing not on the commonly emphasized benefits or economic gains, but the concerns surrounding its integration into everyday life. This discussion centers on deeper ethical questions and the evolving relationship between humans and machines. AI, in many ways, serves as a reflection of the human identity and the uniqueness of human cognition Such as infants being able to intuitively recognize a caregiver’s face within days. While AI systems require vast datasets and immense computational effort to approximate this same ability. Yet, AI exhibits strengths where human limitations emerge such as processing and analyzing large volumes of data with precision and consistency. The aim of this paper is neither to lambast technological advancement nor to champion it uncritically. Rather, to highlight the issues which will arise as AI becomes more adopted. highlighting the domains in which each excels, considering how this interaction might evolve and how intelligence both artificial and human is defined, understood, and reimagined in light of these developments. Ultimately, the paper investigates not just what AI can do, but what its rise reveals about the nature of human thought and the values that shape future technological integration.

One pitfall that lies at the heart of defining intelligence is the innate bias to superimpose so-called human faculties of intelligence, as a form of confirmation bias. This can be seen even before AI, demonstrated in the arguments that Crawford proposes, that AI is neither artificial nor intelligent \[1\]. Crawford uses the example of the case of Clever Hans, a horse that appeared to know how to do basic arithmetic, but in reality just relied on the facial expression of its trainer to stop counting once it reached the desired answer. While Hans could not truly learn how to count in the way people expected him to, the fame and notoriety this spectacle created was immense at the start of the 20th century in many newspapers of the time \[2\]. This attention surrounding AI and speculations on its capabilities can be seen through many industries, with an estimated amount of investments in AI being around 140 billion dollars per year since 2019 \[3\]. Thus the onus placed on AI development to further progress in its capabilities, increasing its practical value. While at the same time, there are also issues with AI being able to fully relate in the field of communication with AI chatbots.   
While machines are more sophisticated than horses, this can also be a contributing factor for people being less hesitant on what these systems can do. This is in part due to many AI systems that consumers directly interact with, that being different forms of chatbots. Chatbots such as ChatGPT-4 have been shown to pass multiple different Turing tests, where behavioral and personality tests are statistically indistinguishable from human responses \[4\]. ChatGPT has also implemented forms of sentiment analysis on human text of various product views, using a sentiment analysis scoring system \[5\]. While it might seem that AI can seemingly mimic human intellect, this is far from the case as all AI chatbots available have struggled to pick up on forms of sarcasm \[5\]. This lack of picking up on nuanced human text is a seemingly trivial error that in the next few years, could very well be fixed. While picking up on sarcasm does not just apply to AI but also humans, with people oftentimes failing to pick up on sarcasm, even more so via text. The ability to pick up on sarcasm might seem simple to a person, it would be much more difficult for an AI system to replicate human faculties in the same way. There are many factors that a human needs in order to pick up on the use of sarcasm such as tone of voice, facial expressions, shared knowledge, ect. This example shows how humans are more efficient due to being more well rounded abilities and versed than current general AI, with humans being a jack of all trades and master of none. AI on the other hand takes the opposite approach, being able to   outperform humans in specific tasks.    
In 1965, Russian mathematician Alexander Kronrod used chess as the hotbed of experimentation with early AI systems, claiming that chess was the ‘diaspora’ of AI. This meant that games were ideal for AI as they are simple for an AI system to understand mathematically, but were also generate enough intrigue to be theoretically interesting \[6\]. Being able to represent tasks in an AI system is a key component in how efficient AI will be in being able to complete certain tasks. There are plenty of examples of AI outperforming humans in board games such as Go, in which an AI program AlphaGo was able to beat the best Go players in the world \[7\]. There is also the example of IBMs Deep Blue computer in 1997 defeating chess player Garry Kasparov \[6\]. AI has only gotten better at playing different games with the introduction of Neural Networks and reinforcement learning techniques being able to play much more complicated games \[8\]. These examples demonstrate how currently the most effective AI systems are ones that have a specific goal that can be expressed mathematically. It also shows how the field of games is the entrypoint of AI study, as well as being a heavily studied area in the field of AI development. This development has also expanded into other fields, showing how ubiquitous of a tool AI is as well as AIs common strengths.  
AI is well suited for tasks that heavily rely on detecting patterns, making judgments, and optimization \[9\]. AI excels at processing vast amounts of data at high speeds as well as being able to siphon large amounts of data from the internet. Another way in which AI is used is to identify correlations that may be imperceptible to humans. AI also can automate repetitive tasks, reducing human error. These are tasks that are within the AI domain are done by people who are highly skilled workers. This includes clinical laboratory technicians, chemical engineers, optometrists, and power plant operators \[9\].  However, despite these strengths, AI still struggles with tasks that require deep contextual understanding, emotional intelligence, and nuanced decision-making, which remain in the domain of human expertise. Jobs containing these certain aspects are less likely to be impacted by AI. These jobs include teachers, veterinary technicians and entertainers \[9\]. This contrast between the strengths of AI and human cognition underscores the importance of understanding not only what AI can do, but what it cannot. To fully grasp how AI is perceived today, it is essential to revisit the origins of the concept itself and the ambitions that guided its early development.  
To understand AI and how it is viewed in public consciousness, it is paramount to view the history of what AI means and how it was envisioned at its earliest inception. The term AI itself was coined in 1956 in a summer research project proposal at Dartmouth college by John McCarthy, an Assistant Math Professor \[10\]. His ambitious vision for this project was to have, “every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it”. A lot has changed since McCarthy’s time, when AI was merely in its inception. For one, the term itself has become more widespread than ever before, with firms and consumers knowing and unknowingly interacting with AI systems. Thus the goal set upon the field of AI is augmenting the ability of computers to simulate intelligence. Whether AI currently achieves this goal is ambiguous and differs depending on what one identifies intelligence is. This dynamic between humans of having lived experience and with current AI being more specialized to certain tasks. This dichotomy forms the very undergirding at which the misunderstandings of what true intelligence is when comparing humans and AI. With the understanding that AI does not currently possess true generality the ways in which humans do is at its core. 

**AI integration and its concerns**   
There is a development of change which considers the modern era via means of manipulating and innovating the spread of information. The earliest examples of information being transferred can be seen within many ancient cultures via oral traditions being passed down from generation to generation. However, with the invention of the printing press, information could be stored within the confines of pages, where the archival  of information was formed. This spread of information was further extended in the development of the Internet, with knowledge not just spreading physically, but digitally with nearly any piece of information being stored in the average person's pocket. With the adoption of the internet, there became an exponential spread of information and data. Just as the internet became a way for information to spread across the world with astonishing speed, the age of AI further utilizes vast amounts of information stored in the virtual world. The commonality of all forms of AI is that it shifts the burden of information gathering and processing from man to machine. Just as Upton Sinclair raised concern of the industrial revolution with his groundbreaking book, “The Jungle” showing disgusting malpractices in packing factories. This parallels the current ethics of AI, in how there are little to no regulations on the usage of AI. In a world where one day the outcome of a person on trial is in the mechanical hands of a machine rather than man is one in which mankind must be observant.  
One of the main concerns with the rise of AI development is that it will be used to replace people's jobs. This issue of people getting replaced or “phased” out by machines is not a novel concept. From the rise of agriculture in early human history, where man utilized the environment to grow the crops in front of them rather than having to spread out and seek them. As well as during the industrial revolution where man utilized technology instead of livestock, pulling heavy loads and generating energy through utilizing flowing water with mills. These two examples of the development of agriculture and the industrial revolution demonstrate mankind's ability to automate through the means of manipulating objects in the physical world. AI on the other hand, struggles with skills that are found in jobs with more social aspects such as teachers and managers \[9\]. There are also other tasks that AI struggles with in which AI will not be able to quickly replace jobs that involve human morals, physical dexterity, and contextual understanding.  
 Despite these flaws, AI is used in many different fields and industries. One example is how it can be used to reduce human errors in breast cancer screening \[11\]. While the use of AI technology can be used to evaluate certain images, studies show that many people would not go forth with an evaluation if they knew AI was used \[11\]. This lies  at the heart of the issue with AI, in that in some instances it is superior to humans but at the same time not be trusted. The underlying reason is that one cannot place the burden of blame on AI. This is due to the fact that AI is a moral agent and is a tool used by people \[12\]. One of the main reasons for this is that it cannot explain reasonings. Thus some people claim that the  use of AI should not be placed in positions where it can control the outcomes of one’s life. But what about the cases in which humans make decisions that can determine the outcome of people’s lives? Is it that people feel more comfortable in having a person be the morale agent, as they can be held responsible if the outcomes do not fare well. Or is it that currently we do not trust AI until it has become more trustworthy in the public? Once AI has gained better press will it be used in life or death situations? Who will be the agent to blame if AI does perform a miscalculation? While the answers to these questions are out of the scope of this paper, it is important to think about who is ultimately in charge of AI systems when they fail in their intended purpose as non-moral agents in determining life or death consequences in a position of higher authority.   
This same argument can be said for fields in which life or death decisions are made. This comes from the example of a court case in which a lawyer submitted a case brief that was written by ChatGPT. The field of law is a perfect example of where AI tools ride a fine line between being a useful tool and resulting in someone serving an unjust prison sentence. ChatGPT has proven that it is trained on legal issues, being shown to pass the bar exam with a C+ average score \[13\] . While ChatGPT appears to have legal issues in its training, it has also shown to often fabricate or “hallucinate” information on cases or completely make up court cases (AI lawyer paper). However, there is quite a conundrum with the introduction of AI not just by lawyers *i*n the field of law with the use of  the average person. While on one hand it gives people more access to justice, as people who do not have the financial means to a lawyer can prompt tools like ChatGPT for their specific case. But due to ChatGPT not being fully trustworthy, it could lead to people making unwise legal decisions. While there have existed legal tools such as Justicebot, which focus more on specific legal cases of landlord disputes, it is not as versatile as ChatGPT with responses to specific questions, but is far more accurate on legal information \[14\]. 

**Issues of AI (The alternative uses of AI) \-**  
**Feeding the Machine: How Big Data Powers AI and Reshapes Society**    
In the movie “I Robot”, based on the short story “Runaround” by Isaac Asimov, is set in Chicago in the year 2035 in which humans and robots coexist. There exists a set of laws programmed into each robot which follows,” The First Law states, A robot may not injure a human being or, through inaction, allow a human being to come to harm. The Second Law states, A robot must obey the orders given it by human beings except where such orders would conflict with the First Law. The Third Law states, a robot must protect its own existence as long as such protection does not conflict with the First or Second Law”. While these straightforward laws exist in a fictional universe, we are currently only a decade away in which this fictional setting takes place. There are issues surrounding a concrete set of standards of AI regulation that are currently not in place. The results of a lack of standard practice of AI ethics has the potential to put vulnerable people in danger in the hands of those who design and implement AI systems.  
One issue about AI that has not been addressed yet is what really goes into the AI sausage? One of the necessities for large AI models is the need for large amounts of data. Data is the foundation for AI and its continuing development. By having the most access to different types of data in all of human history, it empowers the average person. Within a few clicks on a computer one can find access to many different types of data. From images of dogs on the internet to reddit comments, data can be found virtually anywhere on the internet. While many forms of data online exist, there is also the overabundance of useless data. Not all data generated is necessarily useful or even accessible to the average person. The types of data that are useful include aspects of monetization, drive decision-making, or provide a competitive advantage. These include financial, personal, industrial, and strategic data with the most valuable kinds of data granting economic, political, or technological power. Personal data fuels corporate empires, financial data moves global markets, and classified intelligence can determine the fate of nations. In the internet age, whoever controls the data controls the world, with AI being the catalyst in which powers can exponentially utilize this data.   
Data has been a central component through the development of civilization and humanity. There have been large collections of data throughout history such as census data \[15\]. This data would then be used to make informed decisions such as if a country has enough available men to invade another country. While at the same time this same data could be used for predicting the population growth that would give rise to potential issues. While this data was hard to gather and tedious, given there needed to be a few people surveying a large area, oftentimes overcounting or undercounting. What is also important to note is who had access to this type of information, whereas in the olden days it was kings and royal officials who had access to this information. These quantitative resources ultimately boost those who are at the top with the resourceful means to enact wide ranging change \[16\]. This idea is even more present in modern times, the only difference is that this shift is happening from governmental authorities to large corporations via the usage and collection of data \[17\].  While there is a contrast within modern times, that being how the average person has far greater access to this type of large scale data than people in the past 200 years. Within a few clicks on a computer one can find this type of census data and more. The same rules to the game of power still apply however, even if one has access to these resources, they lack the ability to cause widespread change. With that being said, it is overall better to at least view the same rules of the game that people in power have versus not.  
This data has brought a rise to tech giants, in which these firms are closely tied into various aspects of governments. These include companies such as Tencent, ByteDance, Google, Amazon, Meta, and Microsoft among others. The different aspects of government that these companies help shape is lobbying for new laws as well as enforcing governmental agendas with these companies' technological developments. For example, Tencent (the largest company in the video games industry), has deep ties with China and its governing board the CCP. Tencent has many of these branches tied to the CCP within the company. These policies shape what the company can and cannot do regarding Chinese censorship \[18\]. This does not only affect China and Chinese media but also reaches a wider global audience. This is due to Tencent owning large parts of gaming companies prominent in the US Riot Games, Supercell, and Epic Games \[18\].  There is also the Chinese based company ByteDance, which operates the popular social media app TikTok. There was an attempt to ban the app in the US in 2020 under the Trump administration, claiming TikTok was a threat to national security as the Chinese government could have access to US citizens' data if they requested it from ByteDance \[19\]. These two Chinese companies show how with the rise of huge tech firms, global powers both shape and rely on huge tech firms which have influence on a global scale.  
While countries have always used technological might as a sphere of influence on various countries, the means by which they do this thought has changed. One of these changes is the result of different forms of data that these firms utilize for various governments. This comes in the form via big data and how it differs from data used in the past. While the term big data itself varies among many different fields and classifications, it contains three unique features from data \[20\]. These features consist of the three Vs being volume (consisting of enormous quantities of data), velocity (created in real-time) and variety (being structured, semi-structured and unstructured) \[21\]. There are also some other factors that are found in big data but are not uniform among the computer science community such as veracity (the data can be messy, noisy and contain uncertainty and error), value (many insights can be extracted and the data repurposed), variability (data whose meaning can be constantly shifting in relation to the context in which they are generated) \[21\]. These unique aspects of big data provide new insights which differ from data, with the huge quantities of data that are being put into the internet. To put into perspective just how much data is being placed on the internet between the start of civilization and 2003 there were 5 exabytes of data, whereas now that information is created every 2 days \[20\]. There also exists different kinds of big data being unstructured data such as chat logs, audio, and images. While big data lends itself to new discoveries that are not found in data, it is not without its issues.   
There are several issues of big data some of which consist of data storage, high resource costs, and data privacy. Being able to store vast amounts of data in one place is nearly impossible as in 2020, there are approximately 40 zettabytes uploaded to the internet each day \[22\]. This amount of information needs to be stored somewhere but as of now, there does not exist a place where a single system could store anywhere close to this amount of information. Thus the only way to store these massive amounts of data is by utilizing cloud storage, dispersing the spread of data among many different systems and servers. This lets different devices access large amounts of data while not having to deal with the issues of storage and running various programs. However, cloud storage makes tracing big data far more complicated than having it on a single system. Thus it can be more accessible to malicious parties that seek to exploit or utilize forms of cloud stored big data. These motives for stealing big data exist due to the high computational costs that are associated with storing the information. Not to mention the resources needed to syphon vast amounts of data. Such examples of big data breaches due in part to cloud storage are shown in the massive Equifax data breach, where on September 8, 2017, the consumer credit company reported that 148 million US citizens personal data was compromised which included Social Security numbers, drivers license numbers, and dates of birth \[23\]. While these risks and issues of big data being the hijacking of valuable user data as well as national concerns, the rewards of big data for firms are highly beneficial. Even more so with the combination of AI being able to supercharge the effects of big data and big data providing training data for AI models to make even better decisions.    
With the transformation of data in terms of size, scale and complexity over the course of time has brought with it new challenges. From the rise of the tech giants and the ways in which big data gathered by tech giants shape and are used by governments to push various agendas. As well as how big data is constructed and the issues with implementing and storing big data. While the utilization of big data by firms and governments is out of the hands of the average person, these types of power imbalances were never new to begin with. As more and more people become informed by these types of technological power imbalances people will start to speak out against these issues. One of these issues that have raised vocal concern around the internet is how social media consumers are affected by the use of AIs, becoming their own downfall by being the ones to feed these machines with big data.  

**The use of AI in targeted advertising**   
Users on various social media sites are unknowingly feeding these AIs via the organic generation of big data. This use of big data into these AI programs is just one form of big data and how AI is used to feed off of social media posts as well as the metadata on each post. The use cases of AI with this data is utilized to categorize posts, analyze user behaviors, and generate posts \[24\]. This raises many important concerns that will shape how users interact with and are affected by not only social media but the internet at large. With the categorization of posts, this will affect the types of consent users will view in their “algorithms” which in this context is referring to what content the backend systems of different social media apps feed users based on a multitude of factors. With the categorization of posts it will be even easier for higher powers to either promote or suppress certain content based posts. The use of AI to track user behaviors creates many ethical concerns regarding bias and discrimination against certain people. As well as raise user privacy concerns regarding how their data is being scrapped and used on AI projects. The last point is how with the ability of AI powered bots to generate posts, this will create a plague of bots on many social media sites.  
With the categorization of posts, it is instrumental to understand the why of the question. While there are many answers to such a question as well as the implications, one definitive reason is to appeal to advertisers, which are the real customers of social media. One hard truth in life is that there is no free lunch. This saying certainly applies to social media sites as they need to generate some value for someone. Social media platforms such as Twitter struggle to remain breaking even in 2024 \[25\]. The main reason for this is that, as the name implies, social media needs many users to generate any value. People are not going to want to sign up to a service right off the bat if they are going to have to pay for it and where there are people there are people to sell to. This also means that social media services must not only have many users but must also find ways to grab their attention and retain them. Thankfully this work is done by the users themselves, as all social media sites are in fact, just digital town squares where public interactions take place. To understand the importance of these social media sites and thus the traditional town square and its interactions with advertisers, one must understand the history of the town square itself and the interactions with advertisers.  
Advertising is a practice which has existed far before the 21th century. However the form and ideology of advertising has shifted. This shift transformed the simple nature of announcing one's products, to that of demandings the public’s attention on a wider scale \[26\]. This demand of people's attention started with using wit and humor such as in a 1693 Dutch guideline advertising handbook \[27\]. The shift from politely asking for one's attention to that of a demand for it can be seen at the turn of the 20th century. This can be seen from examples of New York city and Paris, both of which were rife with posters that plagued the streets. Citizens were mixed in their views of advertising in these metropolis areas. Some citizens viewed these advertising posters as a way of creativity and human expression, while others viewed it as visual noise that cluttered the view of the natural city. This was a contentious issue at the time that brought up new issues of what society should be paying attention to and what the means are respectable and which are not. This began with the rise of charlatans who began to draw spectacles for monetary gain. Such examples as the infamous P.T. Barnum created spectacles such as his infamous “fiji mermaid”, which in reality was just the head of a monkey on a fish \[26\]. While it seems ridiculous that people would fall for such schemes, as Barnum himself puts it,” You can fool most of the people most of the time”, which rings true even more so in the internet age.          
These ideas of creating spectacles mirror modern times in which banner ads and bots advertising various products garner attention. Banner ads have been used at the start of the internet and have a massive market cap, where in 2003 generated 7.3 million dollars \[28\]. According to the same study, the findings of what makes an effective banner ad conclude that ads with many animations and that are not big and simple are not as effective in generating high CTR (click-through rate) \[28\]. This shows how with the rise of banner ads, they have become both ineffective for the firms and a nuisance for the consumer. The use of bots is prolific online, shown in a study in which analyzed how bots commented more in Twitch chats than human users \[29\].  As well as bots having making up roughly 10% on social media sites such as twitter and twitch \[30\]. While these nuances on the internet have existed before the AI tools, with the introduction of AI in the advertising space, it raises several concerns on user privacy and security.   
Now this relates to AI categorizing posts and how it is annoying to have ads targeted at someone. The categorization of certain users is already being used in the form of targeted ads \[31\] . The companies placing these ads want to draw in crowds that are focused on their specific niche. The social media companies in turn want advertisers to spend money to place posts, in which they will only place posts if it is making them a profit. Thus it is vital from the social media companies perspective to utilize AI classifying algorithms to select certain users based on their posts and engagement with the site by sending targeted ads showing how their site generates more revenue for the companies via ad placement. Categorizing posts also goes hand in hand with being able to categorize users to said posts. As advertising is a business that relies on being able to capture the attention of a select demographic of a certain product. The main gaps in advertising is who is the target audience that would be interested in buying a specific product and how platforms or means to reach these future customers on. One task that AI does really well is being able to predict, classify, and cluster trends in data. This data is valuable to these companies as the more they know about their customers the more data they have on them, the more accurately they can predict the customer.   
During the golden age of the newspaper from the 16th to early 20th century were the dominant forms of news communication. These papers were sold at a rock bottom price and the companies making them were losing money on every paper sold \[32\]. They made up for this loss by attracting more eyes on their paper as it grew in influence in that everyone could afford one. This then drew companies to begin putting ads as well as people being able to place personal ads in the papers. Social media is the modern day version of this system. If one decided to pay a bit more, they would be able to attract attention to themselves via the paid personal ads section. Social media parallels this same idea, that if one pays then they will be able to draw more attention. This is done by services such as Twitter, which have a system where if one pays a monthly subscription fee, then they will have priority in comment sections as well as generate more pull in the algorithm versus those who don't pay.  
AI interacts with this system by being able to generate posts via bots. As such, the people who actually want to generate attention are people running the AI bots themselves, which only exist to draw attention. This creates a dynamic in which social media, and thus the internet is filled with soulless bots lurking around. Another way that AI chatbots are being utilized is not by specific social media platforms themselves to drive user engagement, but also as a way of advertising. This can also be seen on platforms such as Reddit. The main appeal of Reddit with advertisers targeting this platform in particular is how human driven the discussion topics are. These discussion topics create an open forum for anyone to comment on, with many of these forum posters either asking questions or addressing other users' responses. Where the AI chatbot advertising takes place is how it could be used to seem as a natural person suggesting that a certain product could help them with their problem. An example of this could start with the thread about how a user is trying to find a glue to fix their expensive figure. Wherein, the advertiser AI chatbot could be used to detect these types of questions and respond to the person saying that they should try their glue to fix the problem. The infiltration of these advertising AI chatbots could ruin the reputation of these sites, which would reduce the amount of users on sites like Reddit. In the long run this would become a lose-lose situation for all parties involved. The users, with how they are bombarded with synthetic advertisements, the websites losing massive amounts of users thus reducing the sites value for advertisers, and the advertisers themselves with less potential customers to advertise to.  
These collective sentiments lead to the rise in the belief of the dead internet theory. The dead internet theory became a popular conspiracy theory in the late 2010s which claims that the internet was controlled by bots, AI, and content curated algorithms pushed by big tech. As well as claims that most users one interacts with in the internet are not real people but bots (Dead internet theory). While this theory is largely disproven, it does however raise valid concerns that the use of AI on the internet at large. These concerns include drowning out organic human engagement, the spread of misinformation and the weakening of online communities (Dead internet theory). With the internet becoming more and more commercialized, AI can be used as a means to an end or as a catalyst of spam and online solicitation. This works in the short term for social media platforms in that advertisers will think there are a lot more users. Thus paying a premium for those which are just bots, lifeless users that will never be able to buy products. In the long term, advertisers will be able to recognize that there are not as many people on these social media platforms as they claim, thus creating a legal storm that could spell trouble for social media platforms. What will happen when the cord is unplugged from social media and what will rise up from the rouble and take their places as the virtual town square. I believe that AI itself will decide to take over the real mostly real user engagement on these social media platforms, giving way to a new rise of mental illness of unhealthy parasocial relationships.   
       

**The effect AI has on creating parasocial relationships in valuable individuals**  
One such recent problem that AI has contributed to is the social isolation and encouragement of unhealthy parasocial relationships. While parasocial relationships have existed since the early days of televisions and celebrity culture, AI shifts the perception of exclusivity and plays more into realizing people's fantasies. One way that this is being used currently is via online celebrities or other famous figures automating text responses. Recently, Meta has rolled out their own version of AI chatbots that aim to mimic celebrity figures or people with different character traits and backgrounds \[33\]. One such user who tested the Meta AI chatbots remarked how they were mostly unhelpful, that just looking information up or using a general AI chatbot would be more useful \[34\]. Many of these personalized Meta AI chatbots were only limited to a certain domain of expertise, such as the chief only providing cooking tips. One might suspect that these companies' goals are not to make the user's experience on the platform more effective but to drive their user engagement up by attempting to simulate real people. This simulation of real people is not just made for a novel or interesting way to engage with such services, but can be seen as an attempt to drive engagements on social media platforms.  
Parasocial relationships have existed long before the advent of AI. This has been through social media and even more so with the covid 19 epidemic. This incident led many to self isolate from others for a prolonged period. With this isolation, there became a need for social connection and technology became the default method. While many socialized via video chat applications, many opted into binge-watching movies and shows, creating parasocial bonds \[35\]. The development of parasocial relationships became a way for people to cope with the lack of social opportunities. While these one-sided parasocial relationships could be beneficial when it could be used as group one sided parasocial relationships. This could be used as a common form of communication especially when bonding over a familiar figure. However, issues arise when the relationship becomes pseudo two-sided with the rise of AI chatbots, being able to interact with users directly.    
There are many negative implications in developing parasocial relationships that are further exacerbated through the introduction of AI companion chatbots. These AI companion chatbots' purpose is to serve as a substitute for human connection, with companies such as Nomi claiming to have their bots trained as generalist model with emotional capabilities \[36\]. While previously parasocial relationships would form with TV and celebrity figures, now that AI has come into the picture, people who have unstable mental states will be affected \[37\]. However, differences between developing parasocial relationships between TV and AI is how AI is far more interactive. This is due to how users can prompt all different kinds of responses from these AI chatbots. While the end point of AI is to ultimately become generalized, with AI having multiple functionalities rather than a specialized tool. One of these issues is how AI chatbots do not have strong safeguards in preventing unethical interactions.   
These unethical interactions involve users of the AI chatbot program prompting specific programs in specific ways in order to test whether the program will respond with anything harmful to the user. Such examples include AI chatbot company Nomi, with their bot being able to be prompted into telling users to commit suicide as well as providing the methodologies \[38\]. This response is documented by a user, who documented how there were little to no safeguards on this specific AI chatbot. While no one was harmed in this previous case there was however a case in which a 14 year old boy used another AI companion bot from Character.AI, which allegedly convinced the boy to commit suicide \[38\]. This case ultimately resulted in the plaintiff, (the mother of the boy) retracting her case after falling flat on multiple claims \[39\]. These two firms Nomi and Character.AI both make similar claims about how censoring these AI chatbots violates first amendment principles \[36\], \[39\]. While it is too early to say what courts opinions on AI chatbots will be in the future, with the given cases present it appears that AI committing or in aiding illegal behavior will not be held responsible by their parent companies, but rather the users. On the other hand, the company OpenAI views users safety as a main concern with ChatGPT. This has been shown though the AIs internal logic as when dangerous responses are prompted, it will either block the message or it will flag the question, disabling certain functionalities and prioritizing user safety \[40\].      

**Conclusion**    
This research has demonstrated that many of the problems presented by AI are not brand new but history repeating itself. While these issues might not be new, the solutions that future researchers come up with in the realm of AI ethics and safety will be. From discussions of AI’s current capabilities and its limitations, AI will become more and more integrated into everyday life. However with this new integration of AI there comes a few issues. This includes the threat of company controlled monopolies of user fed Big Data, raising concerns over user privacy. As well as how this data will be used back onto the consumer in the form of ad recommendation and the threat of AI chatbots infiltrating internet discourse. With the rise and normalization of AI this leads to the threat of increase of parasocial relationships with AI, targeting vulnerable individuals. As AI becomes more ubiquitous, society must confront these issues with a critical eye to ensure that technological progress remains at its core, centered to the overall benefit of mankind by maintaining ethical responsibilities.

Bibliography  
\[1\]	K. Crawford, *The Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence*. Yale University Press, 2021\.  
\[2\]	“Berlin’s Wonderful Horse New York Times.pdf.” Accessed: Mar. 18, 2025\. \[Online\]. Available: https://timesmachine.nytimes.com/timesmachine/1904/09/04/101396572.pdf  
\[3\]	T. Babina, A. Fedyk, A. He, and J. Hodson, “Artificial intelligence, firm growth, and product innovation,” *J. Financ. Econ.*, vol. 151, p. 103745, Jan. 2024, doi: 10.1016/j.jfineco.2023.103745.  
\[4\]	Q. Mei, Y. Xie, W. Yuan, and M. O. Jackson, “A Turing test of whether AI chatbots are behaviorally similar to humans,” *Proc. Natl. Acad. Sci. U. S. A.*, vol. 121, no. 9, p. e2313925121, doi: 10.1073/pnas.2313925121.  
\[5\]	M. Belal, J. She, and S. Wong, “Leveraging ChatGPT As Text Annotation Tool For Sentiment Analysis,” Jun. 18, 2023, *arXiv*: arXiv:2306.17177. Accessed: Nov. 10, 2024\. \[Online\]. Available: http://arxiv.org/abs/2306.17177  
\[6\]	N. Ensmenger, “Is chess the drosophila of artificial intelligence? A social history of an algorithm,” *Soc. Stud. Sci.*, vol. 42, no. 1, pp. 5–30, 2012\.  
\[7\]	C. Koch, “How the Computer Beat the Go Player,” *Sci. Am. Mind*, vol. 27, no. 4, pp. 20–23, 2016\.  
\[8\]	G. Skinner and T. Walmsley, “Artificial Intelligence and Deep Learning in Video Games A Brief Review,” in *2019 IEEE 4th International Conference on Computer and Communication Systems (ICCCS)*, Feb. 2019, pp. 404–408. doi: 10.1109/CCOMS.2019.8821783.  
\[9\]	M. Webb, “The Impact of Artiﬁcial Intelligence on the Labor Market”.  
\[10\]	TechScribe, “A Comprehensive Guide To The History Of Artificial Intelligence: Foundational Concepts And Early Developments.” Accessed: Mar. 18, 2025\. \[Online\]. Available: https://quantumzeitgeist.com/history-of-artificial-intelligence/  
\[11\]	P. Esmaeilzadeh, “Use of AI-based tools for healthcare purposes: a survey study from consumers’ perspectives,” *BMC Med. Inform. Decis. Mak.*, vol. 20, no. 1, p. 170, Jul. 2020, doi: 10.1186/s12911-020-01191-1.  
\[12\]	J.-C. Heilinger, “The Ethics of AI Ethics. A Constructive Critique,” *Philos. Technol.*, vol. 35, no. 3, p. 61, Jul. 2022, doi: 10.1007/s13347-022-00557-9.  
\[13\]	J. Tan, H. Westermann, and K. Benyekhlef, “ChatGPT as an Artificial Lawyer?”.  
\[14\]	K. Y. Iu and V. M.-Y. Wong, “ChatGPT by OpenAI: The End of Litigation Lawyers?,” *SSRN Electron. J.*, 2023, doi: 10.2139/ssrn.4339839.  
\[15\]	“Census-taking in the ancient world \- Office for National Statistics.” Accessed: Apr. 01, 2025\. \[Online\]. Available: https://www.ons.gov.uk/census/2011census/howourcensusworks/aboutcensuses/censushistory/censustakingintheancientworld  
\[16\]	R. Rottenburg, S. E. Merry, S.-J. Park, and J. Mugler, *The World of Indicators: The Making of Governmental Knowledge through Quantification*. Cambridge University Press, 2015\.  
\[17\]	“How Private Tech Companies Are Reshaping Great Power Competition,” Johns Hopkins SAIS. Accessed: Apr. 01, 2025\. \[Online\]. Available: https://sais.jhu.edu/kissinger/programs-and-projects/kissinger-center-papers/how-private-tech-companies-are-reshaping-great-power-competition  
\[18\]	“How The Chinese Government Controls Tencent, the Seventh Largest Company in the World,” Vision Times. Accessed: Apr. 02, 2025\. \[Online\]. Available: https://www.visiontimes.com/2021/07/30/how-the-chinese-government-controls-tencent-the-seventh-largest-company-in-the-world.html  
\[19\]	A. Kwande, “TikTok Under Watch: A Look Into The TikTok Ban and Its Implications on National Security and Free Speech,” Jul. 2023, doi: 10.57912/23773785.v1.  
\[20\]	R. Hooper, “Big Data: What Is It and How Can Academic Libraries Use It?,” *BIG DATA*.  
\[21\]	“What makes Big Data, Big Data? Exploring the ontological characteristics of 26 datasets.” Accessed: Apr. 02, 2025\. \[Online\]. Available: https://journals.sagepub.com/doi/epub/10.1177/2053951716631130  
\[22\]	A. K. Sandhu, “Big data with cloud computing: Discussions and challenges,” *Big Data Min. Anal.*, vol. 5, no. 1, pp. 32–40, Mar. 2022, doi: 10.26599/BDMA.2021.9020016.  
\[23\]	J. E. Thomas, “A Case Study Analysis of the Equifax Data Breach 1 A Case Study Analysis of the Equifax Data Breach,” 2019, doi: 10.13140/RG.2.2.16468.76161.  
\[24\]	J. Li, Z. Ye, and C. Zhang, “Study on the interaction between big data and artificial intelligence,” *Syst. Res. Behav. Sci.*, vol. 39, no. 3, pp. 641–648, 2022, doi: 10.1002/sres.2878.  
\[25\]	“New Insights Suggest X Is Struggling To Make Money | Social Media Today.” Accessed: Apr. 08, 2025\. \[Online\]. Available: https://www.socialmediatoday.com/news/x-formerly-twitter-struggling-to-make-money/738836/  
\[26\]	S. Schwarzkopf, “What Was Advertising? The Invention, Rise, Demise, and Disappearance of Advertising Concepts in Nineteenth- and Twentieth-Century Europe and America”.  
\[27\]	“Shop and awning banquet \- 1693.” Accessed: Apr. 04, 2025\. \[Online\]. Available: https://www.let.leidenuniv.nl/Dutch//Renaissance/BergWinkelbanquet1693.html  
\[28\]	H. Robinson, A. Wysocka, and C. Hand, “Internet advertising effectiveness,” *Int. J. Advert.*, Jan. 2007, Accessed: Apr. 07, 2025\. \[Online\]. Available: https://www.tandfonline.com/doi/abs/10.1080/02650487.2007.11073031  
\[29\]	“The Social Roles of Bots: Evaluating Impact of Bots on Discussions in Online Communities: Proceedings of the ACM on Human-Computer Interaction: Vol 2, No CSCW.” Accessed: Apr. 07, 2025\. \[Online\]. Available: https://dl.acm.org/doi/abs/10.1145/3274426  
\[30\]	M. Orabi, D. Mouheb, Z. Al Aghbari, and I. Kamel, “Detection of Bots in Social Media: A Systematic Review,” *Inf. Process. Manag.*, vol. 57, no. 4, p. 102250, Jul. 2020, doi: 10.1016/j.ipm.2020.102250.  
\[31\]	X. Zhao *et al.*, “DEAR: Deep Reinforcement Learning for Online Advertising Impression in Recommender Systems,” *Proc. AAAI Conf. Artif. Intell.*, vol. 35, no. 1, Art. no. 1, May 2021, doi: 10.1609/aaai.v35i1.16156.  
\[32\]	S. Vella, “Newspapers,” in *Reading Primary Sources*, 2nd ed., Routledge, 2009\.  
\[33\]	M. Andrejevic and Z. Volcic, “Automated Parasociality: From Personalization to Personification,” *Telev. New Media*, p. 15274764241300436, Nov. 2024, doi: 10.1177/15274764241300436.  
\[34\]	“I tested Meta’s Tom Brady and Kendall Jenner AI chatbots and it was weird | ZDNET.” Accessed: Mar. 20, 2025\. \[Online\]. Available: https://www.zdnet.com/article/i-tested-metas-tom-brady-and-kendall-jenner-ai-chatbots-and-it-was-weird/  
\[35\]	C. L. Jarzyna, “Parasocial Interaction, the COVID-19 Quarantine, and Digital Age Media,” *Hum. Arenas*, vol. 4, no. 3, pp. 413–429, Sep. 2021, doi: 10.1007/s42087-020-00156-0.  
\[36\]	“Common Misconceptions About AI Companions, AI Girlfriends, And AI Friends,” Nomi.ai. Accessed: Apr. 08, 2025\. \[Online\]. Available: https://nomi.ai/ai-today/common-misconceptions-about-ai-companions-ai-girlfriends-and-ai-friends/  
\[37\]	A. M. Rubin, E. M. Perse, and R. A. Powell, “Loneliness, Parasocial Interaction, and Local ℡evision News Viewing,” *Hum. Commun. Res.*, vol. 12, no. 2, pp. 155–180, 1985, doi: 10.1111/j.1468-2958.1985.tb00071.x.  
\[38\]	“An AI chatbot told a user how to kill himself—but the company doesn’t want to ‘censor’ it | MIT Technology Review.” Accessed: Apr. 01, 2025\. \[Online\]. Available: https://www.technologyreview.com/2025/02/06/1111077/nomi-ai-chatbot-told-user-to-kill-himself/  
\[39\]	M. Garcia, N. Shazeer, and D. F. Adiwarsana, “UNITED STATES DISTRICT COURT MIDDLE DISTRICT OF FLORIDA ORLANDO DIVISION”.  
\[40\]	A. Blum, “Breaking ChatGPT with Dangerous Questions Understanding how ChatGPT Prioritizes Safety, Context, and Obedience”.

       

